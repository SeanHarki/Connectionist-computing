{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Multi-layer preceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    def __init__(self, NI, NH, NO):  \n",
    "        self.in_num = NI              \n",
    "        self.hidden_num = NH          \n",
    "        self.out_num = NO              \n",
    "        self.W1 = np.array        \n",
    "        self.W2 = np.array        \n",
    "        self.dW1 = np.array      \n",
    "        self.dW2 = np.array      \n",
    "        self.Z1 = np.array       \n",
    "        self.Z2 = np.array       \n",
    "        self.bias_lower = np.array       \n",
    "        self.bias_upper = np.array      \n",
    "        self.dBias_lower = np.array    \n",
    "        self.dBias_upper = np.array    \n",
    "        self.H = np.array  \n",
    "        self.O = np.array  \n",
    "        \n",
    "        \n",
    "       \n",
    "    def randomise(self): \n",
    "        self.W1 = np.array((np.random.uniform(low=0, high=1, size=(self.in_num, self.hidden_num))).tolist())\n",
    "        self.W2 = np.array((np.random.uniform(low=0, high=1, size=(self.hidden_num, self.out_num))).tolist())\n",
    "        \n",
    "\n",
    "        # set dW1 and dW2 to all zeroes.\n",
    "        self.dW1 = np.dot(self.W1, 0)\n",
    "        self.dW2 = np.dot(self.W2, 0)\n",
    "        \n",
    "    def softmax_function(self, x):\n",
    "        exps = np.exp(x - np.max(x))\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def sigmoid_function(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def derivative_sigmoid_function(self, x):\n",
    "        return np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "    \n",
    "    \n",
    "    def tanh_function(self, x):\n",
    "        return np.tanh(x)\n",
    "    def derivative_tanh_function(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "       \n",
    "      \n",
    "    \n",
    "    def forward(self, I, activation):\n",
    "   \n",
    "        if activation == 'sigmoid_function':\n",
    "            \n",
    "            self.Z1 = np.dot(I, self.W1)\n",
    "            self.H = self.sigmoid_function(self.Z1)\n",
    "            self.Z2 = np.dot(self.H, self.W2)\n",
    "            self.O = self.sigmoid_function(self.Z2)\n",
    "    \n",
    "        elif activation == 'tanh_function' :\n",
    "            self.Z1 = np.dot(I, self.W1) \n",
    "            self.H = self.tanh_function(self.Z1)\n",
    "            self.Z2 = np.dot(self.H, self.W2) \n",
    "            self.O = self.Z2\n",
    "            \n",
    "        return self.O\n",
    "    \n",
    "    \n",
    "    \n",
    "    def backward(self, I, target, activation):\n",
    "        output_error = np.subtract(target, self.O)  \n",
    "        if activation == 'sigmoid_function' : \n",
    "            activation_O=self.derivative_sigmoid_function(self.Z2)\n",
    "            activation_H=self.derivative_sigmoid_function(self.Z1)\n",
    "            \n",
    "        elif activation == 'tanh_function' :\n",
    "            activation_O=self.derivative_tanh_function(self.Z2)\n",
    "            activation_H=self.derivative_tanh_function(self.Z1)\n",
    "            \n",
    "        elif activation == 'softmax_function' :\n",
    "            activation_O=self.softmax_function(self.Z2)\n",
    "            activation_H=self.softmax_function(self.Z1)\n",
    "            \n",
    "        dw2_a = np.multiply(output_error, activation_O)\n",
    "        self.dW2 = np.dot(self.H.T, dw2_a)\n",
    "        dw1_a=np.multiply(np.dot(dw2_a, self.W2.T), activation_H)\n",
    "        self.dW1=np.dot(I.T,dw1_a)\n",
    "        return np.mean(np.abs(output_error))\n",
    "\n",
    "\n",
    "    \n",
    "    def updateWeights(self, learningRate):\n",
    "        self.W1 = np.add(self.W1,learningRate * self.dW1)\n",
    "        self.W2 = np.add(self.W2,learningRate * self.dW2)\n",
    "        self.dW1 = np.array\n",
    "        self.dW2 = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XOR function**\n",
    "\n",
    "Train an MLP with 2 inputs, 3-4+ hidden units and one output on the\n",
    "following examples (XOR function):\n",
    "\n",
    "((0, 0), 0)\n",
    "\n",
    "((0, 1), 1)\n",
    "\n",
    "((1, 0), 1)\n",
    "\n",
    "((1, 1), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(inputs, outputs, max_epochs, learning_rate, NH):\n",
    "    NI = 2\n",
    "    NO = 1\n",
    "    NN = MLP(NI, NH, NO)\n",
    "    NN.randomise()\n",
    "    print('\\nMax Epoch: ' + str(max_epochs))\n",
    "    print('\\nLearning Rate: ' + str(learning_rate))\n",
    "    print('\\nNumber of hidden units: ' + str(NH))\n",
    "    print('\\nBefore Training: ')\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        NN.forward(inputs[i],'sigmoid_function')\n",
    "        prediction =0\n",
    "        if(NN.O > 0.5):\n",
    "                prediction = 1 \n",
    "        print('Actual:\\t {}  Output:\\t {}  Prediction:\\t {}'.format(str(outputs[i]), str(NN.O), str(prediction)))\n",
    "    \n",
    "    print('\\nTraining:\\n')\n",
    "    \n",
    "    for i in range(0, max_epochs):\n",
    "        NN.forward(inputs,'sigmoid_function')\n",
    "        error = NN.backward(inputs, outputs,'sigmoid_function')\n",
    "        NN.updateWeights(learning_rate)\n",
    "\n",
    "        if (i + 1) % (max_epochs / 25) == 0:\n",
    "            print('Error at epoch: ' + str(i + 1) + ' is' + str(error))\n",
    "            \n",
    "    print('\\n Test :\\n')\n",
    "    \n",
    "    accuracy=float(0)\n",
    "    for i in range(len(inputs)):\n",
    "        prediction = 0\n",
    "        NN.forward(inputs[i],'sigmoid_function')\n",
    "        if(NN.O > 0.5):\n",
    "                prediction = 1 \n",
    "        print('Actual: {} Output: {}  Prediction: {}'.format(str(outputs[i]), str(NN.O), str(prediction)))\n",
    "        if(outputs[i][0]==0):\n",
    "            accuracy+=1-NN.O[0]\n",
    "        elif(outputs[i][0]==1):\n",
    "            accuracy+=NN.O[0]\n",
    "            \n",
    "    values_to_add = {'Learning Rate': learning_rate,'Accuracy': accuracy/4, 'Error': 1-accuracy/4}\n",
    "    row_to_add = pd.Series(values_to_add, name=NH)\n",
    "    \n",
    "    return row_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=10000\n",
    "learn_rate=[1.0,0.8,0.6,0.4,0.2,0.02]\n",
    "Output_list = []\n",
    "df = pd.DataFrame(columns=['Learning Rate', 'Accuracy', 'Error'])\n",
    "NH=[3,6,12,24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(NH)):\n",
    "    for j in range(len(learn_rate)):\n",
    "        x = XOR(inputs, outputs , iteration, learn_rate[j], NH[i])\n",
    "        df = df.append(x)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Error == df.Error.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NH3 = df[:6]\n",
    "NH6 = df[6:12]\n",
    "NH12 = df[12:18]\n",
    "NH24 = df[18:]\n",
    "\n",
    "# line 1 points\n",
    "x1 = NH3['Learning Rate']\n",
    "y1 = NH3['Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"3 Hidden units\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = NH6['Learning Rate']\n",
    "y2 = NH6['Error']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"6 Hidden Units\")\n",
    "\n",
    "# line 3 points\n",
    "x3 = NH12['Learning Rate']\n",
    "y3 = NH12['Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x3, y3, label = \"12 Hidden units\")\n",
    "\n",
    "# line 2 points\n",
    "x4 = NH24['Learning Rate']\n",
    "y4 = NH24['Error']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x4, y4, label = \"24 Hidden Units\")\n",
    "\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Error')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Max epoch = 10000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SIN function**\n",
    "\n",
    "Generate 500 vectors containing 4 components each. The value of each\n",
    "component should be a random number between -1 and 1. These will be\n",
    "your input vectors. The corresponding output for each vector should be\n",
    "the sin() of a combination of the components. Specifically, for inputs:\n",
    "[x1 x2 x3 x4]\n",
    "the (single component) output should be:\n",
    "sin(x1-x2+x3-x4)\n",
    "\n",
    "Train an MLP with 4 inputs, at least 5 hidden units and one output\n",
    "on 400 of these examples and keep the remaining 100 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIN(inputs, outputs, max_epochs, learning_rate, NH):\n",
    "\n",
    "    NI = 4\n",
    "    NO = 1\n",
    "    NN = MLP(NI, NH, NO)\n",
    "    NN.randomise()\n",
    "    print('\\nMax Epoch: ' + str(max_epochs))\n",
    "    print('\\nLearning Rate: ' + str(learning_rate))\n",
    "    print('\\nNumber of hidden units: ' + str(NH))\n",
    "    print('\\nBefore Training: ')\n",
    "\n",
    "    for i in range(400):\n",
    "        NN.forward(inputs[i],'tanh_function')\n",
    "        print('Target:\\t{}\\t Output:\\t {}'.format(str(outputs[i]),str(NN.O)))\n",
    "    print('Training:\\n')\n",
    "    \n",
    "    \n",
    "#    training process\n",
    "    train_error=float(0)\n",
    "    for i in range(0, max_epochs):\n",
    "        error = 0\n",
    "        NN.forward(inputs[:400],'tanh_function')\n",
    "        error = NN.backward(inputs[:400], outputs[:400],'tanh_function')\n",
    "        NN.updateWeights(learning_rate)\n",
    "       #prints error every 5% of epochs\n",
    "        if (i + 1) % (max_epochs / 25) == 0:\n",
    "            print('Error at Epoch ' + str(i + 1) + ' is ' + str(error))\n",
    "            train_error = error\n",
    "    \n",
    "    difference=float(0)\n",
    "    suum = float(0)\n",
    "    output = []\n",
    "    expected = []\n",
    "    print('\\n Test :\\n')\n",
    "    for i in range(400, len(inputs)):\n",
    "        NN.forward(inputs[i], 'tanh_function')\n",
    "        print('Actual: {}  Predicted: {}'.format(str(outputs[i]), str(NN.O)))\n",
    "        difference+=np.abs(outputs[i][0]-NN.O[0])\n",
    "        output.append(NN.O)\n",
    "        expected.append(outputs[i])\n",
    "\n",
    "    test_error = difference/100\n",
    "    print('\\ntestError:{}'.format(difference/100))\n",
    "    \n",
    "    values_to_add = {'Learning Rate': learning_rate, 'Test Error': test_error, 'Train Error': train_error}\n",
    "    row_to_add = pd.Series(values_to_add, name=NH)\n",
    "    \n",
    "    return row_to_add, expected, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=10000\n",
    "learn_rate=[0.002, 0.004, 0.006, 0.008]\n",
    "trainerrorlist=[]\n",
    "outputlist=[]\n",
    "expectedlist=[]\n",
    "df1 = pd.DataFrame(columns=['Learning Rate', 'Test Error', 'Train Error'])\n",
    "NH=[10,20,40,80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(213)\n",
    "inputs = []\n",
    "outputs = []\n",
    "for i in range(0, 500):\n",
    "    four_inputs_vector = list(np.random.uniform(-1.0, 1.0, 4))\n",
    "    four_inputs_vector = [float(four_inputs_vector[0]),float(four_inputs_vector[1]),float(four_inputs_vector[2]),float(four_inputs_vector[3])]\n",
    "    inputs.append(four_inputs_vector)\n",
    "\n",
    "inputs=np.array(inputs)\n",
    "\n",
    "for i in range(500):\n",
    "        outputs.append(np.sin([inputs[i][0] - inputs[i][1] + inputs[i][2] - inputs[i][3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(NH)):\n",
    "    for j in range(len(learn_rate)):\n",
    "        x = SIN(inputs, outputs, iteration, learn_rate[j], NH[i])\n",
    "        df1 = df1.append(x[0])\n",
    "        expectedlist=x[1]\n",
    "        outputlist= x[2]\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line 1 points\n",
    "x1 =list(range(100))\n",
    "y1 =  expectedlist\n",
    "# plotting the line 1 points \n",
    "plt.scatter(x1, y1, label = \"Actual\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = list(range(100))\n",
    "y2 = outputlist\n",
    "# plotting the line 2 points \n",
    "plt.scatter(x2, y2, label = \"Predicted\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Prediction number')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Value')\n",
    "# Set a title of the current axes.\n",
    "plt.title('sigmoid - Max epoch = 10000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['Test Error'] == df1['Test Error'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NH5 = df1[:4]\n",
    "NH10 = df1[4:8]\n",
    "NH15= df1[8:12]\n",
    "NH20 = df1[12:16]\n",
    "NH100 = df1[16:]\n",
    "# line 1 points\n",
    "x1 = NH5['Learning Rate']\n",
    "y1 = NH5['Test Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"10 Hidden units\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = NH10['Learning Rate']\n",
    "y2 = NH10['Test Error']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"20 Hidden Units\")\n",
    "\n",
    "# line 3 points\n",
    "x3 = NH15['Learning Rate']\n",
    "y3 = NH15['Test Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x3, y3, label = \"40 Hidden units\")\n",
    "\n",
    "# line 4 points\n",
    "x4 = NH20['Learning Rate']\n",
    "y4 = NH20['Test Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x4, y4, label = \"80 Hidden units\")\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Test Error')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Max epoch = 10000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NH5 = df1[:4]\n",
    "NH10 = df1[4:8]\n",
    "NH15= df1[8:12]\n",
    "NH20 = df1[12:16]\n",
    "NH100 = df1[16:]\n",
    "# line 1 points\n",
    "x1 = NH5['Learning Rate']\n",
    "y1 = NH5['Train Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"10 Hidden units\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = NH10['Learning Rate']\n",
    "y2 = NH10['Train Error']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"20 Hidden Units\")\n",
    "\n",
    "# line 3 points\n",
    "x3 = NH15['Learning Rate']\n",
    "y3 = NH15['Train Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x3, y3, label = \"40 Hidden units\")\n",
    "\n",
    "# line 4 points\n",
    "x4 = NH20['Learning Rate']\n",
    "y4 = NH20['Train Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x4, y4, label = \"80 Hidden units\")\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Training Error')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Max epoch = 10000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['Test Error'] == df1['Test Error'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NH40= df1[4:8]\n",
    "\n",
    "# line 1 points\n",
    "x1 = NH40['Learning Rate']\n",
    "y1 = NH40['Test Error']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"test error\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = NH40['Learning Rate']\n",
    "y2 = NH40['Train Error']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"train error\")\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Accuracy')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Max epoch = 100000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter recognition\n",
    "\n",
    "Train an MLP on the letter recognition set available in the UCI Machine\n",
    "Learning repository:\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/letterrecognition/letter-recognition.data\n",
    "The first entry of each line is the letter to be recognised (i.e. the\n",
    "target) and the following numbers are attributes extracted from images\n",
    "of the letters (i.e. your input). You can find a description of the set\n",
    "here:\n",
    "http://archive.ics.uci.edu/ml/datasets/Letter+Recognition\n",
    "Split the dataset in a training part containing approximately 4/5 of\n",
    "the records, and a testing part containing the rest.\n",
    "Your MLP should have as many inputs as there are attributes (17), as\n",
    "many hidden units as you want (I suggest to start at ~10) and 26\n",
    "outputs (one for each letter of the alphabet).\n",
    "You should train your MLP for at least 1000 epochs. After training,\n",
    "check how well you can classify the data reserved for testing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_recognition(inputs, output, doutput, max_epochs, learning_rate, NH):\n",
    "    \n",
    "    #train set\n",
    "    training_size = int(len(inputs) * 0.8)\n",
    "    inputs_train=inputs[:training_size]\n",
    "    arr = np.zeros((training_size, 26))\n",
    "    for i, l in enumerate(outputs[:training_size]):\n",
    "        arr[i][l] = 1\n",
    "    outputs_train=arr\n",
    "    \n",
    "    #test set\n",
    "    inputs_test=inputs[training_size:]\n",
    "    \n",
    "    \n",
    "    #training process\n",
    "    NI= 16\n",
    "    NO = 26\n",
    "    \n",
    "    NN = MLP(NI, NH, NO)\n",
    "    NN.randomise()\n",
    "    print('\\nMax Epoch: ' + str(max_epochs))\n",
    "    print('\\nLearning Rate: ' + str(learning_rate))\n",
    "    print('\\nHidden Units: ' + str(NH))\n",
    "    print('\\nTraining Process: ')\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, max_epochs):\n",
    "        NN.forward(inputs_train,'tanh_function')\n",
    "        error = NN.backward(inputs_train, outputs_train,'tanh_function')\n",
    "        NN.updateWeights(learning_rate)\n",
    "    \n",
    "        if (i + 1) % (max_epochs / 25) == 0:\n",
    "            print(' Error at Epoch:\\t' + str(i + 1) + '\\t  is \\t' + str(error))\n",
    "    \n",
    "    \n",
    "    #testing process\n",
    "    def to_character0(outputvector):\n",
    "        listov=list(outputvector)\n",
    "        a=listov.index(max(listov))\n",
    "        return chr(a+ord('A'))\n",
    "    \n",
    "    prediction=[]\n",
    "    for i in range(4000):\n",
    "        NN.forward(inputs_test[i],'tanh_function')\n",
    "        prediction.append(to_character0(NN.O))\n",
    "        \n",
    "       \n",
    "    def to_character(n):\n",
    "        return chr(int(n) + ord('A'))\n",
    "    \n",
    "    correct = {to_character(i): 0 for i in range(26)}\n",
    "    \n",
    "    print('==' * 30)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = sum(correct.values()) / len(prediction)\n",
    "    print('Test sample size: {} | Correctly predicted sample size: {}'.format(len(prediction),sum(correct.values()))) \n",
    "    print('Accuracy: %.3f' % accuracy)\n",
    "    \n",
    "    values_to_add = {'# Hidden units': NH, 'Learning rate': learning_rate, 'Accuracy': accuracy}\n",
    "    row_to_add = pd.Series(values_to_add, name='x')\n",
    "    df =df.append(row_to_add)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "inputs = []\n",
    "outputs = []\n",
    "doutput = []\n",
    "columns=[\"letter\",\"x-box\",\"y-box\",\"width\",\"height\",\"onpix\",\"x-bar\",\"y-bar\",\"x2bar\",\"y2bar\",\"xybar\",\"x2ybr\",\"xy2br\",\"x-ege\",\"xegvy\",\"y-ege\",\"yegvx\"]\n",
    "df_accuracy = pd.DataFrame()  \n",
    "df=pd.read_csv(\"letter-recognition.data\", names=columns)\n",
    "doutput=df[\"letter\"]\n",
    "length = len(df)\n",
    "for i in range(length):\n",
    "    outputs.append(ord(str(doutput[i]))-ord('A'))\n",
    "  \n",
    " \n",
    "inputs=df.drop([\"letter\"], axis=1)\n",
    "inputs=np.array(inputs)\n",
    "inputs=inputs/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_output(output, training_size):\n",
    "    arr = np.zeros((training_size, 26))\n",
    "    for i, l in enumerate(output):\n",
    "        arr[i][l] = 1\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Max Epoch: 100000\n",
      "\n",
      "Learning Rate: 1e-06\n",
      "\n",
      "Hidden Units: 10\n",
      "\n",
      "Training Process: \n",
      " Error at Epoch:\t4000\t  is \t3.7134433291783058\n",
      " Error at Epoch:\t8000\t  is \t2.7313985341723512\n",
      " Error at Epoch:\t12000\t  is \t1.8483671703161313\n",
      " Error at Epoch:\t16000\t  is \t1.6432823892108446\n",
      " Error at Epoch:\t20000\t  is \t1.6002684626388062\n",
      " Error at Epoch:\t24000\t  is \t1.5209414394668876\n",
      " Error at Epoch:\t28000\t  is \t1.2870833882804817\n",
      " Error at Epoch:\t32000\t  is \t0.9124053272229269\n",
      " Error at Epoch:\t36000\t  is \t0.8366477773610058\n",
      " Error at Epoch:\t40000\t  is \t0.6643013496644362\n",
      " Error at Epoch:\t44000\t  is \t0.4554453013213272\n",
      " Error at Epoch:\t48000\t  is \t0.274157430094465\n",
      " Error at Epoch:\t52000\t  is \t0.25532245994154984\n",
      " Error at Epoch:\t56000\t  is \t0.07430169273162411\n",
      " Error at Epoch:\t60000\t  is \t0.0741193343865245\n",
      " Error at Epoch:\t64000\t  is \t0.07407231404032162\n",
      " Error at Epoch:\t68000\t  is \t0.07440650389037215\n",
      " Error at Epoch:\t72000\t  is \t0.07533800100088221\n",
      " Error at Epoch:\t76000\t  is \t0.07573833166828921\n",
      " Error at Epoch:\t80000\t  is \t0.07602959980779397\n",
      " Error at Epoch:\t84000\t  is \t0.07661243026647112\n",
      " Error at Epoch:\t88000\t  is \t0.07761415689080794\n",
      " Error at Epoch:\t92000\t  is \t0.07856495608520342\n"
     ]
    }
   ],
   "source": [
    "iteration=100000\n",
    "learn_rate=[0.000001]\n",
    "NH = [10, 15, 25]\n",
    "for i in range(len(NH)):\n",
    "    for j in range(len(learn_rate)):\n",
    "        print('----------------------------------------------------------------------\\n')\n",
    "        x = letter_recognition(inputs, outputs, doutput, iteration, learn_rate[j], NH[i])\n",
    "        df_accuracy = df_accuracy.append(x)\n",
    "        print('\\n-------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NH10 = df_accuracy[:4]\n",
    "NH15 = df_accuracy[4:8]\n",
    "NH25 = df_accuracy[8:12]\n",
    "#NH24 = df_acc[12:]\n",
    "\n",
    "# line 1 points\n",
    "x1 = NH10['Learning rate']\n",
    "y1 = NH10['Accuracy']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"10 Hidden units\")\n",
    "\n",
    "# line 2 points\n",
    "x2 = NH15['Learning rate']\n",
    "y2 = NH15['Accuracy']\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"15 Hidden Units\")\n",
    "\n",
    "# line 3 points\n",
    "x3 = NH25['Learning rate']\n",
    "y3 = NH25['Accuracy']\n",
    "# plotting the line 1 points \n",
    "plt.plot(x3, y3, label = \"25 Hidden units\")\n",
    "\n",
    "\n",
    "plt.xlabel('Learning rate')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('Accuracy')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Max epoch = 10000')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
